import torch
import torchvision.transforms as transforms
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
import seaborn as sns
import os
from buildCNN import SimpleCNN

# 1. æ¨¡å‹åŠ è½½å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
def load_model(model_path, num_classes=11, device='cpu'):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹ï¼ˆå…¼å®¹PyTorch 2.6+çš„å®‰å…¨åŠ è½½ï¼‰"""
    model = SimpleCNN(num_classes=num_classes)
    
    try:
        if not os.path.exists(model_path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ {model_path} ä¸å­˜åœ¨")
            
        # æ–¹æ³•1ï¼šå…³é—­å®‰å…¨æ¨¡å¼ï¼ˆéœ€ç¡®ä¿æ¨¡å‹æ¥æºå¯ä¿¡ï¼‰
        checkpoint = torch.load(model_path, map_location=device, weights_only=False)
        
        # æ–¹æ³•2ï¼šä½¿ç”¨å®‰å…¨ä¸Šä¸‹æ–‡ï¼ˆPyTorch 2.6+ï¼‰
        # from torch.serialization import safe_globals
        # with safe_globals([torch.nn.modules.loss.CrossEntropyLoss]):
        #     checkpoint = torch.load(model_path, map_location=device)
        
        # åŠ è½½æƒé‡
        if isinstance(checkpoint, dict):
            model.load_state_dict(checkpoint['model_state_dict'])
        else:
            model.load_state_dict(checkpoint)
            
        model.eval()
        model.to(device)
        print(f"âœ… æ¨¡å‹è½½å…¥æˆåŠŸ: {model_path}")
        return model
        
    except Exception as e:
        print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
        print("å°è¯•è§£å†³æ–¹æ¡ˆ:")
        print("1. ç¡®ä¿æ¨¡å‹æ–‡ä»¶æœªæŸå")
        print("2. ä½¿ç”¨ torch.save(model.state_dict(), ...) é‡æ–°ä¿å­˜æ¨¡å‹")
        print("3. å¦‚æœä¿¡ä»»æ¨¡å‹æ¥æºï¼Œè®¾ç½® weights_only=False")
        return None
    
# 2. å›¾åƒé¢„å¤„ç†å‡½æ•°
def get_transform():
    """è¿”å›ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„é¢„å¤„ç†æµç¨‹"""
    return transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))  # MNISTæ ‡å‡†åŒ–å‚æ•°
    ])

# 3. é¢„æµ‹å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
def predict_single_image(model, image, transform=None, device='cpu'):
    """
    å¢å¼ºç‰ˆå•å›¾åƒé¢„æµ‹å‡½æ•°
    æ”¯æŒè¾“å…¥ç±»å‹: PIL.Image | np.ndarray | torch.Tensor
    è¿”å›: (é¢„æµ‹ç±»åˆ«, ç½®ä¿¡åº¦, æ‰€æœ‰ç±»åˆ«æ¦‚ç‡)
    """
    try:
        # è¾“å…¥ç±»å‹è½¬æ¢
        if isinstance(image, np.ndarray):
            if image.dtype != np.uint8:
                image = (np.clip(image, 0, 1) * 255).astype(np.uint8)
            image = Image.fromarray(image, mode='L')
        elif isinstance(image, torch.Tensor):
            image = image.squeeze().cpu().numpy()
            image = ((image * 0.3081 + 0.1307) * 255).astype(np.uint8)  # åæ ‡å‡†åŒ–
            image = Image.fromarray(image, mode='L')
        elif not isinstance(image, Image.Image):
            raise ValueError("è¾“å…¥å¿…é¡»æ˜¯PIL.Imageã€np.ndarrayæˆ–torch.Tensor")
        
        # ç¡®ä¿å›¾åƒå°ºå¯¸
        if image.size != (28, 28):
            image = image.resize((28, 28), Image.LANCZOS)
        
        # åº”ç”¨é¢„å¤„ç†
        if transform is None:
            transform = get_transform()
        image_tensor = transform(image).unsqueeze(0).to(device)
        
        # é¢„æµ‹
        with torch.no_grad():
            outputs = model(image_tensor)
            probabilities = torch.softmax(outputs, dim=1)
            confidence, predicted = torch.max(probabilities, 1)
            
        return predicted.item(), confidence.item(), probabilities.cpu().squeeze()
        
    except Exception as e:
        print(f"âš ï¸ é¢„æµ‹å‡ºé”™: {str(e)}")
        return -1, 0.0, None

# 4. æµ‹è¯•å›¾åƒç”Ÿæˆå™¨ï¼ˆå¢å¼ºç‰ˆï¼‰
def create_test_images():
    """ç”Ÿæˆæ›´å…¨é¢çš„æµ‹è¯•å›¾åƒé›†"""
    test_images = []
    rng = np.random.RandomState(42)  # å›ºå®šéšæœºç§å­
    
    # 1. çº¯ç©ºç™½
    blank = np.zeros((28, 28), dtype=np.uint8)
    test_images.append(("çº¯ç©ºç™½", blank))
    
    # 2. ä½å™ªå£°ç©ºç™½
    noisy_blank = rng.uniform(0, 30, (28, 28)).astype(np.uint8)
    test_images.append(("ä½å™ªå£°ç©ºç™½", noisy_blank))
    
    # 3. é«˜å™ªå£°ç©ºç™½
    high_noise = rng.uniform(0, 100, (28, 28)).astype(np.uint8)
    test_images.append(("é«˜å™ªå£°ç©ºç™½", high_noise))
    
    # 4-8. ç®€å•æ•°å­— (1, 3, 5, 7, 9)
    digits = {
        "æ•°å­—0": lambda x, y: ((x == 7) | (x == 21)) & (y >= 5) & (y <= 23) | 
                         ((y == 5) | (y == 23)) & (x >= 7) & (x <= 21),
        "æ•°å­—1": lambda x, y: (x == 14) & (y >= 5) & (y <= 23),
        "æ•°å­—2": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 14) & (x == 21) & (y >= 5) | (y >= 14) & (x == 7) & (y <= 23),
        "æ•°å­—3": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 5),
        "æ•°å­—4": lambda x, y: (y == 14) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 5) | (y >= 5) & (x == 7) & (y <= 14),
        "æ•°å­—5": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 14) | (y >= 5) & (x == 7) & (y <= 14),
        "æ•°å­—6": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 14) | (y >= 5) & (x == 7) & (y <= 23),
        "æ•°å­—7": lambda x, y: (y == 5) & (x >= 7) & (x <= 21) | 
                          (y <= 23) & (x == 21) & (y >= 5),
        "æ•°å­—8": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 5) | (y >= 5) & (x == 7) & (y <= 23),
        "æ•°å­—9": lambda x, y: ((y == 5) | (y == 14) | (y == 23)) & (x >= 7) & (x <= 21) |
                         (y <= 23) & (x == 21) & (y >= 5) | (y >= 5) & (x == 7) & (y <= 14)
    }
    
    
    xx, yy = np.meshgrid(np.arange(28), np.arange(28))
    for name, func in digits.items():
        digit = np.where(func(xx, yy), 255, 0).astype(np.uint8)
        test_images.append((name, digit))
    
    # 9. éƒ¨åˆ†å¡«å……
    partial = np.zeros((28, 28), dtype=np.uint8)
    partial[10:18, 10:18] = 128
    test_images.append(("éƒ¨åˆ†å¡«å……", partial))
    
    # 10. è¾¹ç¼˜æ¡ˆä¾‹
    edge_case = np.zeros((28, 28), dtype=np.uint8)
    edge_case[:, :4] = 200  # å·¦ä¾§è¾¹ç¼˜
    test_images.append(("è¾¹ç¼˜å¡«å……", edge_case))
    
    return test_images

# 5. å¯è§†åŒ–å‡½æ•°ï¼ˆå¢å¼ºç‰ˆï¼‰
def visualize_predictions(model, test_images, transform, device, save_dir="predictions"):
    """å¢å¼ºç‰ˆå¯è§†åŒ–ï¼ŒåŒ…å«æ¦‚ç‡åˆ†å¸ƒå’Œæ··æ·†çŸ©é˜µ"""
    os.makedirs(save_dir, exist_ok=True)
    class_names = [str(i) for i in range(10)] + ['ç©ºç™½']
    
    def get_true_class(name):
        name = str(name).lower()
        if "ç©ºç™½" in name or "blank" in name:
            return 10
        digits = ''.join(c for c in name if c.isdigit())
        return int(digits) if digits else 10
    
    # æ”¶é›†é¢„æµ‹ç»“æœ
    y_true = []
    y_pred = []
    all_probs = []
    
    plt.figure(figsize=(18, 12))
    
    for idx, (name, image) in enumerate(test_images):
        pred_class, confidence, probs = predict_single_image(
            model, image, transform, device
        )
        true_class = get_true_class(name)
        
        y_true.append(true_class)
        y_pred.append(pred_class)
        all_probs.append(probs.numpy() if probs is not None else np.zeros(11))

        # åœ¨matplotlibç»˜å›¾å‰æ·»åŠ ä¸­æ–‡å­—ä½“è®¾ç½®
        plt.rcParams['font.sans-serif'] = ['SimHei']  # æŒ‡å®šé»˜è®¤å­—ä½“
        plt.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºé—®é¢˜
        
        # ç»˜åˆ¶å­å›¾
        plt.subplot(5, 4, idx + 1)
        plt.imshow(image, cmap='gray')
        color = 'green' if pred_class == true_class else 'red'
        plt.title(f'{name}\né¢„æµ‹: {class_names[pred_class]}\nç½®ä¿¡åº¦: {confidence:.2f}', 
                 color=color)
        plt.axis('off')
        
        # ä¿å­˜é”™è¯¯æ ·æœ¬
        if pred_class != true_class:
            Image.fromarray(image).save(f"{save_dir}/wrong_{name.replace(' ', '_')}.png")
    
    # ç»˜åˆ¶æ··æ·†çŸ©é˜µ
    plt.subplot(5, 4, 20)
    cm = confusion_matrix(y_true, y_pred)
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
                xticklabels=class_names, 
                yticklabels=class_names)
    plt.title("æ··æ·†çŸ©é˜µ")
    plt.tight_layout()
    plt.savefig(f"{save_dir}/prediction_summary.png")
    plt.show()
    
    # æ‰“å°è¯¦ç»†æŠ¥å‘Š
    print("\nğŸ“Š é¢„æµ‹ç»“æœç»Ÿè®¡:")
    for i, (name, _) in enumerate(test_images):
        print(f"{name:>12}: çœŸå®={class_names[y_true[i]]}, é¢„æµ‹={class_names[y_pred[i]]}, ç½®ä¿¡åº¦={all_probs[i][y_pred[i]]:.2f}")

# 6. ä¸»å‡½æ•°
def main():
    # åˆå§‹åŒ–
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹ï¼ˆä¿®æ”¹ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ï¼‰
    model_path = "Models/mnist_cnn_v1.pth"  
    model = load_model(model_path, num_classes=11, device=device)
    if model is None:
        return
    
    # è·å–é¢„å¤„ç†æµç¨‹
    transform = get_transform()
    
    # ç”Ÿæˆæµ‹è¯•å›¾åƒ
    test_images = create_test_images()
    
    # å¯è§†åŒ–é¢„æµ‹ç»“æœ
    visualize_predictions(model, test_images, transform, device)
    
    # æ¨¡å‹éªŒè¯æµ‹è¯•
    test_model_outputs(model, device)

# 7. æ¨¡å‹éªŒè¯å‡½æ•°
def test_model_outputs(model, device):
    """éªŒè¯æ¨¡å‹è¾“å…¥è¾“å‡ºæ˜¯å¦ç¬¦åˆé¢„æœŸ"""
    print("\nğŸ” æ­£åœ¨éªŒè¯æ¨¡å‹ç»“æ„...")
    
    # æµ‹è¯•æ ‡å‡†è¾“å…¥
    dummy_input = torch.randn(1, 1, 28, 28).to(device)
    try:
        with torch.no_grad():
            output = model(dummy_input)
            assert output.shape == (1, 11), "è¾“å‡ºå½¢çŠ¶åº”ä¸º(1,11)"
            probs = torch.softmax(output, dim=1)
            assert torch.allclose(probs.sum(dim=1), torch.tensor(1.0)), "æ¦‚ç‡å’Œåº”ä¸º1"
        print("âœ… æ¨¡å‹éªŒè¯é€šè¿‡")
        return True
    except Exception as e:
        print(f"âŒ æ¨¡å‹éªŒè¯å¤±è´¥: {str(e)}")
        return False

if __name__ == "__main__":
    main()
    print("\nâœ¨ æµ‹è¯•å®Œæˆï¼æ£€æŸ¥predictions/ç›®å½•ä¸‹çš„ç»“æœ")