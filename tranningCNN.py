import torch
import torchvision
import torchvision.transforms as transforms
import os
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from torch.utils.data import DataLoader, ConcatDataset
#from buildCNN import SimpleCNN
from PIL import Image

if __name__ == '__main__':
    # æ‰€æœ‰è®­ç»ƒä»£ç æ”¾åœ¨è¿™é‡Œ

    class SimpleCNN(nn.Module):
        def __init__(self, num_classes=11):  # 0-9 æ•¸å­— + ç©ºç™½é¡
            super(SimpleCNN, self).__init__()
            self.conv1 = nn.Conv2d(1, 32, 3, padding=1)
            self.conv2 = nn.Conv2d(32, 64, 3, padding=1)
            self.pool = nn.MaxPool2d(2, 2)
            self.fc1 = nn.Linear(64 * 7 * 7, 128)
            self.fc2 = nn.Linear(128, num_classes)  # 11 é¡è¼¸å‡º
            self.dropout = nn.Dropout(0.5)
            
        def forward(self, x):
            x = self.pool(torch.relu(self.conv1(x)))
            x = self.pool(torch.relu(self.conv2(x)))
            x = x.view(-1, 64 * 7 * 7)
            x = torch.relu(self.fc1(x))
            x = self.dropout(x)
            x = self.fc2(x)
            return x

    # è‡ªå®šç¾©ç©ºç™½è³‡æ–™é›†é¡åˆ¥
    class BlankDataset(torch.utils.data.Dataset):
        def __init__(self, num_samples=10000, transform=None):
            self.num_samples = num_samples
            self.transform = transform
            
        def __len__(self):
            return self.num_samples
        
        def __getitem__(self, idx):
            image = np.zeros((28, 28), dtype=np.float32)
            
            if np.random.random() < 0.3:
                noise_type = np.random.choice(["gaussian", "uniform", "line", "dot"])
                if noise_type == "gaussian":
                    image += np.random.normal(0, 0.05, (28, 28))
                elif noise_type == "uniform":
                    image += np.random.uniform(0, 0.1, (28, 28))
                elif noise_type == "line":
                    for _ in range(1):
                        x = np.random.randint(28)
                        image[x] = np.random.rand(28) * 0.2
                elif noise_type == "dot":
                    for _ in range(random.randint(5, 15)):
                        x, y = random.randint(0, 27), random.randint(0, 27)
                        image[x, y] = random.random() * 0.5
                
                image = np.clip(image, 0, 1)
            
            image = (image * 255).astype(np.uint8)
            image = Image.fromarray(image, mode='L')
            if self.transform:
                image = self.transform(image)
            return image, 10  # ç©ºç™½ç±»æ ‡ç­¾ä¸º10

    # è‡ªå®šç¾©è³‡æ–™é›†åŒ…è£å™¨ï¼Œç”¨æ–¼é‡æ–°æ¨™è¨˜ MNIST
    class MNISTWithBlank(torch.utils.data.Dataset):
        def __init__(self, mnist_dataset):
            self.mnist_dataset = mnist_dataset
            
        def __len__(self):
            return len(self.mnist_dataset)
        
        def __getitem__(self, idx):
            image, label = self.mnist_dataset[idx]
            # MNIST æ¨™ç±¤ä¿æŒ 0-9ï¼Œç©ºç™½é¡å°‡æ˜¯ 10
            return image, label

    # è®¾ç½®éšæœºç§å­ä¿è¯å¯é‡å¤æ€§
    torch.manual_seed(42)
    random.seed(42)
    np.random.seed(42)

    folder_path = "Models"
    base_filename = "mnist_cnn"
    version = 1

    # ç¡®ä¿Modelsç›®å½•å­˜åœ¨
    os.makedirs(folder_path, exist_ok=True)

    # æŸ¥æ‰¾æœ€æ–°ç‰ˆæœ¬å·
    while os.path.exists(os.path.join(folder_path, f"{base_filename}_v{version}.pth")):
        version += 1

    print(f"ğŸ“¦ æº–å‚™è¨“ç·´æ¨¡å‹ç‰ˆæœ¬: v{version}")

    # æ•°æ®é¢„å¤„ç†å’Œå¢å¼º
    train_transform = transforms.Compose([
        transforms.RandomRotation(5),
        transforms.RandomAffine(degrees=0, translate=(0.05, 0.05)),
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    test_transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.1307,), (0.3081,))
    ])

    # è¼‰å…¥ MNIST è³‡æ–™é›†
    mnist_train_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=True, 
        download=True, 
        transform=train_transform
    )
    mnist_test_dataset = torchvision.datasets.MNIST(
        root='./data', 
        train=False, 
        download=True, 
        transform=test_transform
    )

    # åŒ…è£ MNIST è³‡æ–™é›†
    train_mnist = MNISTWithBlank(mnist_train_dataset)
    test_mnist = MNISTWithBlank(mnist_test_dataset)

    blank_train = BlankDataset(num_samples=6000, transform=train_transform)  # 10% çš„è¨“ç·´è³‡æ–™ç‚ºç©ºç™½
    blank_test = BlankDataset(num_samples=1000, transform=test_transform)   # 10% çš„æ¸¬è©¦è³‡æ–™ç‚ºç©ºç™½

    train_dataset = ConcatDataset([train_mnist, blank_train])
    test_dataset = ConcatDataset([test_mnist, blank_test])

    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset, 
        batch_size=64, 
        shuffle=True,
        num_workers=0,
        pin_memory=True
    )
    test_loader = DataLoader(
        test_dataset, 
        batch_size=64, 
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    print(f"ğŸ“Š è¨“ç·´è³‡æ–™: {len(train_dataset)} ç­†")
    print(f"ğŸ“Š æ¸¬è©¦è³‡æ–™: {len(test_dataset)} ç­†")

    # è¼‰å…¥ä½ çš„ CNN æ¨¡å‹
    model = SimpleCNN(num_classes=11)

    # å°è¯•åŠ è½½æœ€æ–°ç‰ˆæœ¬çš„æ¨¡å‹he
    latest_version = version - 1
    if latest_version > 0:
        latest_model_path = os.path.join(folder_path, f"{base_filename}_v{latest_version}.pth")
        if os.path.isfile(latest_model_path):
            try:
                checkpoint = torch.load(latest_model_path)
                # ä¿®å¤ï¼šå…¼å®¹ä¸¤ç§ä¿å­˜æ ¼å¼
                if isinstance(checkpoint, dict) and 'model_state_dict' in checkpoint:
                    # æ–°æ ¼å¼ï¼šåŒ…å«å®Œæ•´æ£€æŸ¥ç‚¹ä¿¡æ¯
                    model.load_state_dict(checkpoint['model_state_dict'])
                    print(f"âœ… å·²åŠ è½½æ¨¡å‹: {latest_model_path}")
                    print(f"   ä¸Šæ¬¡å‡†ç¡®ç‡: {checkpoint.get('accuracy', 'æœªçŸ¥')}%")
                else:
                    # æ—§æ ¼å¼ï¼šåªåŒ…å«state_dict
                    model.load_state_dict(checkpoint)
                    print(f"âœ… å·²åŠ è½½æ¨¡å‹: {latest_model_path}")
                    print(f"   ä¸Šæ¬¡å‡†ç¡®ç‡: æœªçŸ¥")
            except Exception as e:
                print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

    # 3. ä½¿ç”¨ CPU æˆ– GPU
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ–¥ï¸  ä½¿ç”¨è¨­å‚™: {device}")
    model.to(device)

    # 4. è¨­å®š loss function èˆ‡ optimizer
    import torch.optim as optim
    criterion = torch.nn.CrossEntropyLoss()
    optimizer = optim.Adam(model.parameters(), lr=0.001)
    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)

    def test(model, test_loader, device, save_wrong=False):  # æ·»åŠ save_wrongå‚æ•°
        model.eval()
        correct = 0
        total = 0
        class_correct = [0] * 11
        class_total = [0] * 11
        
        with torch.no_grad():
            for images, labels in test_loader:
                images, labels = images.to(device), labels.to(device)
                outputs = model(images)
                _, predicted = torch.max(outputs.data, 1)
                total += labels.size(0)
                correct += (predicted == labels).sum().item()

                # é”™è¯¯æ ·æœ¬ä¿å­˜é€»è¾‘
                wrong_count = 0
                max_wrong_samples = 50
                
                for i in range(labels.size(0)):
                    label = labels[i].item()
                    class_total[label] += 1
                    pred = predicted[i].item()
                    
                    if pred != label and save_wrong and wrong_count < max_wrong_samples:
                        img = images[i].cpu().numpy().squeeze()
                        img = ((img * 0.3081 + 0.1307) * 255).astype(np.uint8)
                        img = Image.fromarray(img, mode='L')
                        os.makedirs("wrong_preds", exist_ok=True)
                        img.save(f"wrong_preds/wrong_{wrong_count}_true{label}_pred{pred}.png")
                        wrong_count += 1
                    
                    if predicted[i] == labels[i]:
                        class_correct[label] += 1

        accuracy = 100 * correct / total
        print(f'æµ‹è¯•å‡†ç¡®ç‡: {accuracy:.2f}%')
        
        # æ˜¾ç¤ºå„ç±»åˆ«å‡†ç¡®ç‡
        class_names = [str(i) for i in range(10)] + ['ç©ºç™½']
        for i in range(11):
            if class_total[i] > 0:
                class_acc = 100 * class_correct[i] / class_total[i]
                print(f'   ç±»åˆ« {class_names[i]}: {class_acc:.2f}% ({class_correct[i]}/{class_total[i]})')
        
        return accuracy

    print("\nğŸ“‹ è¨“ç·´å‰æ¸¬è©¦:")
    initial_accuracy = test(model, test_loader, device, save_wrong=True)

    # è®­ç»ƒå‚æ•°
    num_epochs = 20
    best_accuracy = initial_accuracy
    patience = 3
    no_improve = 0

    # 5. è¨“ç·´æ¨¡å‹
    for epoch in range(num_epochs):  # è¨“ç·´æ¬¡æ•¸
        model.train()
        running_loss = 0.0
        correct_train = 0
        total_train = 0

        for batch_idx, (images, labels) in enumerate(train_loader):
            images, labels = images.to(device), labels.to(device)

            # æ¸…é™¤æ¢¯åº¦
            optimizer.zero_grad()

            # å‰å‘å‚³æ’­
            outputs = model(images)

            # è¨ˆç®— loss
            loss = criterion(outputs, labels)

            # åå‘å‚³æ’­ + æ›´æ–°æ¬Šé‡
            loss.backward()
            optimizer.step()

            # çµ±è¨ˆ
            running_loss += loss.item()
            _, predicted = torch.max(outputs.data, 1)
            total_train += labels.size(0)
            correct_train += (predicted == labels).sum().item()
            
            # æ¯200å€‹batché¡¯ç¤ºé€²åº¦
            if batch_idx % 200 == 0:
                print(f'Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(train_loader)}, Loss: {loss.item():.4f}')

        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()

        train_accuracy = 100 * correct_train / total_train
        avg_loss = running_loss / len(train_loader)
        print(f'ğŸ“ˆ Epoch {epoch+1}/{num_epochs} å®Œæˆ - Loss: {avg_loss:.4f}, è¨“ç·´æº–ç¢ºç‡: {train_accuracy:.2f}%')
        
        # æ¯3ä¸ªepochæµ‹è¯•ä¸€æ¬¡
        if (epoch + 1) % 3 == 0:
            print(f"\nğŸ“‹ Epoch {epoch+1} æµ‹è¯•:")
            current_accuracy = test(model, test_loader, device, save_wrong=(epoch == num_epochs-1))
            
            # æ—©åœæœºåˆ¶
            if current_accuracy > best_accuracy:
                best_accuracy = current_accuracy
                no_improve = 0
                # ä¿å­˜æœ€ä½³æ¨¡å‹
                best_model_path = os.path.join(folder_path, f"{base_filename}_best.pth")
                torch.save(model.state_dict(), best_model_path)
                print(f"ğŸ’¾ ä¿å­˜æœ€ä½³æ¨¡å‹: {best_model_path}")
            else:
                no_improve += 1
                if no_improve >= patience:
                    print(f"â¹ï¸ æ—©åœè§¦å‘ï¼Œå·²è¿ç»­{no_improve}ä¸ªepochæ²¡æœ‰æ”¹è¿›")
                    break
            print()

    new_model_path = os.path.join(folder_path, f"{base_filename}_v{version}.pth")

    torch.save(model.state_dict(), new_model_path)
    # ä¿å­˜æ¨¡å‹æ—¶æ·»åŠ æ£€æŸ¥ç‚¹
    """
    torch.save({
        'epoch': num_epochs,
        'model_state_dict': model.state_dict(),
        'optimizer_state_dict': optimizer.state_dict(),
        'loss': criterion,
        'accuracy': best_accuracy
    }, new_model_path)
    """
    print(f"âœ… æ¨¡å‹å·²ä¿å­˜ä¸º: {new_model_path}")

    # æœ€çµ‚æ¸¬è©¦
    print("\nğŸ“‹ è¨“ç·´å¾Œæœ€çµ‚æ¸¬è©¦:")
    final_accuracy = test(model, test_loader, device, save_wrong=True)

    print(f"\nğŸ‰ è¨“ç·´å®Œæˆï¼")
    print(f"ğŸ“Š æ”¯æ´é¡åˆ¥: 0-9 æ•¸å­— + ç©ºç™½é¡")
    print(f"ğŸ¯ æœ€ä½³æµ‹è¯•å‡†ç¡®ç‡: {best_accuracy:.2f}%")
    print(f"ğŸ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: {final_accuracy:.2f}%")

    # ä¿å­˜é¡åˆ¥æ¨™ç±¤å°æ‡‰
    label_map = {i: str(i) for i in range(10)}
    label_map[10] = 'blank'
    print(f"\nğŸ“ é¡åˆ¥å°æ‡‰: {label_map}")

    # é¢„æµ‹å‡½æ•°
    def predict_image(model, image_path, device):
        try:
            img = Image.open(image_path).convert('L').resize((28, 28))
            img_tensor = test_transform(img).unsqueeze(0).to(device)
            with torch.no_grad():
                output = model(img_tensor)
            pred = output.argmax(1).item()
            return label_map.get(pred, "æœªçŸ¥ç±»åˆ«")
        except Exception as e:
            return f"é¢„æµ‹å¤±è´¥: {str(e)}"

    # ç¤ºä¾‹é¢„æµ‹
    test_image_path = "picture/sudoku.jpg"  # æ›¿æ¢ä¸ºå®é™…è·¯å¾„
    if os.path.exists(test_image_path):
        print(f"\nğŸ” æµ‹è¯•å›¾åƒé¢„æµ‹ç»“æœ: {predict_image(model, test_image_path, device)}")
    else:
        print("\nâš ï¸ æœªæ‰¾åˆ°æµ‹è¯•å›¾åƒï¼Œè¯·æ£€æŸ¥è·¯å¾„")